weka-compare-classifiers
========================

This utility simplifies comparing Weka classifiers using many different metrics.  It is a utility to facilitate learning about supervised learning binary classifiers.


The objective of this utility is to show changes in measurement variables of interest over a wide number of binary classifiers on various sized training sets.  There are predefined experiments included which have a broad array of classifiers.  You can apply these experiments to the three data sets included or to your own.  You will find different versions of tree-based algorithms, boosted models, neural networks, k-nearest neighbors, and support vector machines algorithms.  It is possible to compare many different versions of the same category of algorithm like different neural networks or different decision trees and it is also possible to compare algorithms across categories.


This utility was developed with:
Weka 3.7.10 and LibSVM / libsvm.  (You will only need LibSVM / libsvm if you are using the predefined ‘svm.xml’ Weka experiment file or if you make your own experiment files that are using the LibSVM classifier.)
Python 2.7.6 (Preliminary testing has worked on Python 2.6.6)
If you would like to make charts or save .png files, you will need matplotlib.


To run Weka experiments for many different training set sizes for a given data set:
Open runExperiment.py and edit the configuration information.  There are three data sets included (census.arff, bank.arff, and lendingSubset.arff) but you should be able to use any .arff file you choose that is set up for binary classification.  If you’re using your own .arff file, place it in the directory with the scripts and point to it in the configuration section.  Make sure to update your path_to_weka_jar.  If you are using LibSVM, update both the appropriate paths.


name_of_dataset = 'bank'
experiment = 'svm'


path_to_weka_jar = '/Users/Sylvan/weka-3-7-10/weka.jar'
path_to_libsvm = '/Users/Sylvan/weka-3-7-10/libsvm.jar:/Users/Sylvan/wekafiles/packages/LibSVM/LibSVM.jar'


Once you have updated your configuration information, run the python script by typing:
python runExperiment.py


This will generate nine experiment files from the appropriate experiment template via a shell script.  It will also run these nine experiments and generate csv output for each of them.  Running the nine experiments can take some time depending on the size of the data set, the number / type of features in your data set and the types of learning algorithms in the experiment.


To generate a csv file which summarizes a measurement variable over the learning curve, first open the file supervisedLearning.py and modify the appropriate configuration settings.


createPNGs = False # If you set this to True, you need to have matplotlib
showGraphs = False # If you set this to True, you need to have matplotlib
runWekaExperiments = False # If you set this to True, make sure you have configured runExperiment.py


If you want to create .png files or show simple graphs, set the appropriate boolean variable to True. 


Now, go to the list of measurement variables of interest, which are stored in studies.


studies = ['Percent_incorrect', 'Elapsed_Time_training', 'Elapsed_Time_testing', 
        'UserCPU_Time_training','UserCPU_Time_testing', 'F_measure', 'measureNumLeaves']


Modify this list as desired.  You will see a full list of potential metrics just below studies.  Now run the script by typing:
python supervisedLearning.py


You will find a .csv file for each item on the studies list.  You can plot them directly with matplotlib or import them into another application.  Note that these graphs are currently quite simple and are have a legend with long, cryptic names generated by Weka.  In the future, I will map these names to short, descriptive nicknames.  


Here is a list of all of the possible fields that can be included in the list of studies:


fields = ['Key_Dataset', 'Key_Run', 'Key_Scheme', 'Key_Scheme_options', 'Key_Scheme_version_ID', 'Date_time', 'Number_of_training_instances', 'Number_of_testing_instances', 'Number_correct', 'Number_incorrect', 'Number_unclassified', 'Percent_correct', 'Percent_incorrect', 'Percent_unclassified', 'Kappa_statistic', 'Mean_absolute_error', 'Root_mean_squared_error', 'Relative_absolute_error', 
'Root_relative_squared_error', 'SF_prior_entropy', 'SF_scheme_entropy', 'SF_entropy_gain', 'SF_mean_prior_entropy', 'SF_mean_scheme_entropy', 'SF_mean_entropy_gain', 'KB_information', 'KB_mean_information', 'KB_relative_information', 'True_positive_rate', 'Num_true_positives', 'False_positive_rate', 'Num_false_positives', 'True_negative_rate', 'Num_true_negatives', 'False_negative_rate', 'Num_false_negatives', 'IR_precision', 'IR_recall', 'F_measure', 'Matthews_correlation', 'Area_under_ROC', 'Area_under_PRC', 'Weighted_avg_true_positive_rate', 'Weighted_avg_false_positive_rate', 'Weighted_avg_true_negative_rate', 'Weighted_avg_false_negative_rate', 'Weighted_avg_IR_precision', 'Weighted_avg_IR_recall', 'Weighted_avg_F_measure', 'Weighted_avg_matthews_correlation', 'Weighted_avg_area_under_ROC', 'Weighted_avg_area_under_PRC', 'Unweighted_macro_avg_F_measure', 'Unweighted_micro_avg_F_measure', 'Elapsed_Time_training', 'Elapsed_Time_testing', 'UserCPU_Time_training', 'UserCPU_Time_testing', 'Serialized_Model_Size', 
'Serialized_Train_Set_Size', 'Serialized_Test_Set_Size', 'Coverage_of_Test_Cases_By_Regions', 'Size_of_Predicted_Regions', 'Summary', 'measureTreeSize', 'measureNumLeaves', 'measureNumRules']


To create your own experiment template:
Create an experiment in the Weka Experimenter.  Change Results Destination to CSV file.  Name it template.csv.  Change Experiment type to Train / Test Percentage Split (data randomized).  Note that I ran many experiments with the cross-validation (10 folds 10 times) but you need at least two folds or 50% of the data for this.  Change Train percentage to 47.0.  This sounds arbitrary but kept everything easy.  I have been changing the Number of Repetitions to 5 but you can make this number whatever you want.  Add a dataset to your Experiment.  Add as many algorithms as you would like.  Save your experiment as an XML file.


Open your XML experiment file and make the following changes:
Make sure that on the line with template.arff that there is no path included.  Make the line look like the line below.


<object class="java.io.File" name="0">template.arff</object>


Now search the file for csv.  Make your file look like this:
<object class="java.lang.String" name="1">template.csv</object>
      </object>
      <object class="java.io.File" name="outputFile">templates/raw/template.csv</object>


Make sure that you have no path for the top template.csv and the full path in the bottom templates/raw/template.csv.  If you’re uncertain, open one of the existing templates and search for arff and csv and match those lines.


Now move the file to the templates directory and make sure you are pointing to it in the runExperiment.py file as described above.  If your file is named “abc.xml”, you will change line in runExperiment.py to:
experiment = 'abc'


Good luck and please let me know if you have questions or comments.  Thanks very much.